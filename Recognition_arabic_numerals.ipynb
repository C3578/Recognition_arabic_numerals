{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognition_arabic_numerals",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/C3578/Recognition_arabic_numerals/blob/master/Recognition_arabic_numerals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PwMPMlB8GaDy",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5bJziNvTcIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9EVKJXlTYSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root = '...'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e1kC8OirO8nU",
        "colab": {}
      },
      "source": [
        "def letters_extract(image_file: str, out_size=28):\n",
        "    img = cv2.imread(image_file)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    output = img.copy()\n",
        "\n",
        "    letters = []\n",
        "    for idx, contour in enumerate(contours):\n",
        "        (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "        if hierarchy[0][idx][3] == 0:\n",
        "            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
        "            letter_crop = gray[y:y + h, x:x + w]\n",
        "\n",
        "            size_max = max(w, h)\n",
        "            letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
        "            if w > h:\n",
        "                y_pos = size_max//2 - h//2\n",
        "                letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
        "            elif w < h:\n",
        "\n",
        "                x_pos = size_max//2 - w//2\n",
        "                letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
        "            else:\n",
        "                letter_square = letter_crop\n",
        "\n",
        "            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))\n",
        "\n",
        "    letters.sort(key=lambda x: x[0], reverse=False)\n",
        "\n",
        "    return letters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u8kMk3SrYbm-",
        "colab": {}
      },
      "source": [
        "class MNISTNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n",
        "        self.ac1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.ac1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "mnist_net_2 = MNISTNet(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZIk4gQnYbx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ded29359-2dad-4adc-84f7-7fd5ba34c93c"
      },
      "source": [
        "mnist_net_2.load_state_dict(torch.load('gdrive/My Drive/.../mnist_net_2.pth'))\n",
        "mnist_net_2.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTNet(\n",
              "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (ac1): Sigmoid()\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jvde1vwIATLN",
        "colab": {}
      },
      "source": [
        "def emnist_predict_img(model, img):\n",
        "    a = torch.Tensor(img.reshape(784))\n",
        "    outputs = model(a).tolist()\n",
        "    return outputs.index(max(outputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JNk-ySTHO6h7",
        "colab": {}
      },
      "source": [
        "def ocr(model, image_file):\n",
        "    letters = letters_extract(image_file)\n",
        "    s_out = ''\n",
        "    for i in range(len(letters)):\n",
        "        dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
        "        s_out += str(emnist_predict_img(model, letters[i][2]))\n",
        "        if (dn > letters[i][1]*1.5):\n",
        "            s_out += ' '\n",
        "    print(s_out[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v_xiQ-YT2lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d85ec76f-1be9-4b41-9759-a08714c43d86"
      },
      "source": [
        "ocr(mnist_net_2, data_root + 'arab_11.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9876543210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-BZ1GzoPgS0",
        "colab": {}
      },
      "source": [
        "ocr(mnist_net_2, input('Путь к файлу:'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJIC444hL8EX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}